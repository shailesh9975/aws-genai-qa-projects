# ğŸ¤– Project 01 â€“ AWS GenAI Chatbot using Bedrock (Claude + Streamlit + Lambda)

## ğŸ“š Overview
This project demonstrates how to build a **Generative AI Chatbot** powered by **AWS Bedrock (Anthropic Claude 3.5 Sonnet)**.  
It allows real-time AI conversations using a **Streamlit frontend** and an **AWS Lambda backend** that securely calls the Bedrock Runtime API.

---

## ğŸ§© Project Structure
project_01_chatbot_bedrock/
â”‚
â”œâ”€â”€ app.py # Streamlit UI for local chat interaction
â”œâ”€â”€ lambda_function.py # AWS Lambda backend function
â”œâ”€â”€ test_bedrock_chatbot.py # Local test script to validate Bedrock connection
â”œâ”€â”€ function.zip # Deployment package for Lambda
â”œâ”€â”€ requirements.txt # Python dependencies
â”œâ”€â”€ .gitignore # Ignore unnecessary files
â””â”€â”€ README.md # Project documentation

User (Streamlit UI)
â”‚
â–¼
AWS Lambda Function
â”‚
â–¼
AWS Bedrock Runtime â”€â”€â–¶ Claude 3.5 Sonnet Model
â”‚
â–¼
Returns AI response to Streamlit interface



---

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Prerequisites
Before you start, make sure you have:
- Python **3.9+**
- An **AWS account** with **Bedrock access**
- IAM role with permission: `bedrock:InvokeModel`
- **Streamlit** installed locally

---

### 2ï¸âƒ£ Local Environment Setup
Clone the repo:
```bash
git clone https://github.com/shailesh9975/aws-genai-qa-projects.git
cd aws-genai-qa-projects/project_01_chatbot_bedrock


python3 -m venv venv
source venv/bin/activate     # On Windows: venv\Scripts\activate



pip install -r requirements.txt

streamlit run app.py
Then open in your browser:
ğŸŒ http://localhost:8501

Ask questions like:

â€œWhat is Generative AI QA testing?â€

â€œExplain AWS Bedrock in simple terms.â€

ğŸ§  Lambda Deployment
Step 1: Prepare Deployment Package
zip -r function.zip lambda_function.py

Step 2: Deploy on AWS Lambda

Go to AWS Console â†’ Lambda â†’ Create Function

Choose â€œAuthor from scratchâ€

Runtime: Python 3.10

Upload function.zip

Set environment variables (if needed)

Attach IAM role with bedrock:InvokeModel permission

ğŸ§ª Local Testing

Run:

python test_bedrock_chatbot.py


Sample Output:

ğŸ¤– Claude Response:
Generative AI QA testing ensures the quality and reliability of AI systems that generate content...

ğŸ“Š Key Learnings

âœ… How to invoke AWS Bedrock models via boto3
âœ… Building a Streamlit-based GenAI frontend
âœ… Structuring cloud-based AI inference pipelines
âœ… Testing and validating Claude model outputs for QA

ğŸŒ Future Enhancements

 Add multi-model support (Claude, Titan, Llama)

 Integrate conversation history with DynamoDB

 Deploy Streamlit app on AWS EC2 or Streamlit Cloud

 Add prompt evaluation metrics for GenAI QA

ğŸ‘¨â€ğŸ’» Author

Shailesh Gaikwad
QA Engineer | AI/ML Validation | GenAI QA Tester
ğŸ”— GitHub
 | LinkedIn

â€œTesting AI is the art of teaching machines to think better.â€ ğŸ§ 

